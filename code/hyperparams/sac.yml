widowx_reacher-v1:
  # env_wrapper: utils.wrappers.TimeFeatureWrapper
  n_timesteps: 500000
  normalize: true
  policy: 'MlpPolicy'
  learning_rate: 0.0003
  buffer_size: 1000000
  learning_starts: 100
  batch_size: 256
  tau: 0.005
  gamma: 0.99
  train_freq: 1
  gradient_steps: 1
  n_episodes_rollout: -1
  optimize_memory_usage: False
  ent_coef: "auto"
  target_update_interval: 1
  target_entropy: "auto"
  use_sde: False
  sde_sample_freq: -1
  use_sde_at_warmup: False
  create_eval_env: False
  policy_kwargs: None  # "dict(log_std_init=-2, net_arch=[64, 64])"
  device: "auto"
  _init_setup_model: True


widowx_reacher-v3:
  # env_wrapper: utils.wrappers.TimeFeatureWrapper
  n_timesteps: 500000
  normalize: true
  policy: 'MlpPolicy'
  learning_rate: 0.0003
  buffer_size: 1000000
  learning_starts: 100
  batch_size: 256
  tau: 0.005
  gamma: 0.99
  train_freq: 1
  gradient_steps: 1
  n_episodes_rollout: -1
  optimize_memory_usage: False
  ent_coef: "auto"
  target_update_interval: 1
  target_entropy: "auto"
  use_sde: False
  sde_sample_freq: -1
  use_sde_at_warmup: False
  create_eval_env: False
  policy_kwargs: None  # "dict(log_std_init=-2, net_arch=[64, 64])"
  device: "auto"
  _init_setup_model: True


widowx_reacher-v38:
  # env_wrapper: utils.wrappers.TimeFeatureWrapper
  n_timesteps: 500000
  normalize: true
  policy: 'MlpPolicy'
  learning_rate: 0.0003
  buffer_size: 1000000
  learning_starts: 100
  batch_size: 256
  tau: 0.005
  gamma: 0.99
  train_freq: 1
  gradient_steps: 1
  n_episodes_rollout: -1
  optimize_memory_usage: False
  ent_coef: "auto"
  target_update_interval: 1
  target_entropy: "auto"
  use_sde: False
  sde_sample_freq: -1
  use_sde_at_warmup: False
  create_eval_env: False
  policy_kwargs: None  # "dict(log_std_init=-2, net_arch=[64, 64])"
  device: "auto"
  _init_setup_model: True
